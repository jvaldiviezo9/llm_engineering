{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import openai\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "MODEL_GPT = 'deepseek/deepseek-chat'\n",
    "# MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94069891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease explain what this code does and why:\\nyield from {book.get(\"author\") for book in books if book.get(\"author\")}\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d21163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepseek/deepseek-chat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fde46a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you're testing looks like you're testing! If you have any questions or need assistance, feel free to ask. How can I help you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# Regular version\n",
    "import openai\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "client = openai.OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://router.requesty.ai/v1\"\n",
    "    )\n",
    "\n",
    "# Define model\n",
    "model = \"deepseek/deepseek-chat\"\n",
    "\n",
    "# Send request\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    max_tokens=150,\n",
    "    stream=True,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"test\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print streamed response\n",
    "output_text = \"\"\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        output_text += content\n",
    "        print(content, end=\"\", flush=True)\n",
    "\n",
    "print() # Print a newline at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db76fd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__orig_bases__', '__orig_class__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__stream__', '__subclasshook__', '__weakref__', '_cast_to', '_client', '_decoder', '_is_protocol', '_iter_events', '_iterator', 'close', 'response']\n",
      "Help on Stream in module openai object:\n",
      "\n",
      "class Stream(typing.Generic)\n",
      " |  Stream(*, cast_to: 'type[_T]', response: 'httpx.Response', client: 'OpenAI') -> 'None'\n",
      " |  \n",
      " |  Provides the core interface to iterate over a synchronous stream response.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Stream\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self) -> 'Self'\n",
      " |  \n",
      " |  __exit__(self, exc_type: 'type[BaseException] | None', exc: 'BaseException | None', exc_tb: 'TracebackType | None') -> 'None'\n",
      " |  \n",
      " |  __init__(self, *, cast_to: 'type[_T]', response: 'httpx.Response', client: 'OpenAI') -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self) -> 'Iterator[_T]'\n",
      " |  \n",
      " |  __next__(self) -> '_T'\n",
      " |  \n",
      " |  __stream__(self) -> 'Iterator[_T]'\n",
      " |  \n",
      " |  close(self) -> 'None'\n",
      " |      Close the response and release the connection.\n",
      " |      \n",
      " |      Automatically called if the response body is read to completion.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_decoder': 'SSEBytesDecoder', 'response': 'httpx.R...\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[~_T],)\n",
      " |  \n",
      " |  __parameters__ = (~_T,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |      Parameterizes a generic class.\n",
      " |      \n",
      " |      At least, parameterizing a generic class is the *main* thing this method\n",
      " |      does. For example, for some generic class `Foo`, this is called when we\n",
      " |      do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |      \n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo(Generic[T]): ...`.\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List attributes and methods of the response object\n",
    "print(dir(response))\n",
    "\n",
    "# Get detailed information about the response object\n",
    "help(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14fd67da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This code snippet is written in Python and uses a combination of a generator expression and the `yield from` statement. Let's break it down step by step:\n",
       "\n",
       "### Code Explanation:\n",
       "```python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension.\n",
       "   - It iterates over each `book` in the `books` collection.\n",
       "   - For each `book`, it retrieves the value associated with the key `\"author\"` using `book.get(\"author\")`.\n",
       "   - The `if book.get(\"author\")` condition ensures that only non-empty (truthy) author values are included in the set.\n",
       "   - The result is a set of unique author names (since sets automatically remove duplicates).\n",
       "\n",
       "2. **`yield from`**:\n",
       "   - `yield from` is used to delegate the generation of values to another iterable (in this case, the set created by the set comprehension).\n",
       "   - It yields each element of the set one by one, effectively turning the generator into a sequence of author names.\n",
       "\n",
       "### Why Use This Code?\n",
       "- **Purpose**: The code is designed to extract and yield unique author names from a collection of books.\n",
       "- **Efficiency**: Using a set comprehension ensures that duplicate author names are automatically filtered out, and `yield from` efficiently yields each unique author name without needing to store the entire set in memory at once.\n",
       "- **Use Case**: This could be useful in scenarios where you want to process or iterate over unique authors from a large dataset of books without loading all the data into memory at once.\n",
       "\n",
       "### Example:\n",
       "Suppose `books` is a list of dictionaries like this:\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book1\", \"author\": \"AuthorA\"},\n",
       "    {\"title\": \"Book2\", \"author\": \"AuthorB\"},\n",
       "    {\"title\": \"Book3\", \"author\": \"AuthorA\"},\n",
       "    {\"title\": \"Book4\", \"author\": \"\"},\n",
       "    {\"title\": \"Book5\", \"author\": \"AuthorC\"},\n",
       "]\n",
       "```\n",
       "\n",
       "The code would yield:\n",
       "- `\"AuthorA\"` (only once, even though it appears in two books)\n",
       "- `\"AuthorB\"`\n",
       "- `\"AuthorC\"`\n",
       "\n",
       "The empty author in `Book4`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code snippet is written in Python and uses a combination of a generator expression and the `yield from` statement. Let's break it down step by step:\n",
      "\n",
      "### Code Explanation:\n",
      "```python\n",
      "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
      "```\n",
      "\n",
      "1. **Set Comprehension**:\n",
      "   - `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension.\n",
      "   - It iterates over each `book` in the `books` collection.\n",
      "   - For each `book`, it retrieves the value associated with the key `\"author\"` using `book.get(\"author\")`.\n",
      "   - The `if book.get(\"author\")` condition ensures that only non-empty (truthy) author values are included in the set.\n",
      "   - The result is a set of unique author names (since sets automatically remove duplicates).\n",
      "\n",
      "2. **`yield from`**:\n",
      "   - `yield from` is used to delegate the generation of values to another iterable (in this case, the set created by the set comprehension).\n",
      "   - It yields each element of the set one by one, effectively turning the generator into a sequence of author names.\n",
      "\n",
      "### Why Use This Code?\n",
      "- **Purpose**: The code is designed to extract and yield unique author names from a collection of books.\n",
      "- **Efficiency**: Using a set comprehension ensures that duplicate author names are automatically filtered out, and `yield from` efficiently yields each unique author name without needing to store the entire set in memory at once.\n",
      "- **Use Case**: This could be useful in scenarios where you want to process or iterate over unique authors from a large dataset of books without loading all the data into memory at once.\n",
      "\n",
      "### Example:\n",
      "Suppose `books` is a list of dictionaries like this:\n",
      "```python\n",
      "books = [\n",
      "    {\"title\": \"Book1\", \"author\": \"AuthorA\"},\n",
      "    {\"title\": \"Book2\", \"author\": \"AuthorB\"},\n",
      "    {\"title\": \"Book3\", \"author\": \"AuthorA\"},\n",
      "    {\"title\": \"Book4\", \"author\": \"\"},\n",
      "    {\"title\": \"Book5\", \"author\": \"AuthorC\"},\n",
      "]\n",
      "```\n",
      "\n",
      "The code would yield:\n",
      "- `\"AuthorA\"` (only once, even though it appears in two books)\n",
      "- `\"AuthorB\"`\n",
      "- `\"AuthorC\"`\n",
      "\n",
      "The empty author in `Book4`\n"
     ]
    }
   ],
   "source": [
    "# Markdown version\n",
    "import openai\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "client = openai.OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://router.requesty.ai/v1\"\n",
    ")\n",
    "# Define model\n",
    "model = \"deepseek/deepseek-chat\"\n",
    "\n",
    "# Send request\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    max_tokens=500,\n",
    "    stream=True,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": question}]\n",
    "    )\n",
    "\n",
    "# Display streamed response in Markdown\n",
    "output_text = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in response:\n",
    "    if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        output_text += content\n",
    "        display_handle.update(Markdown(output_text)) # Update Markdown display\n",
    "print(output_text) # Optionally print the final output to console as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
